# ğŸœ Itadaki ML - Recipe Calorie Prediction System

_"Itadaki" signifie "bon appÃ©tit" en japonais_

## ğŸ“ Projet de certification DEV IA - Alyra

Ce projet constitue le **projet final** de la certification **DÃ©veloppeur Intelligence Artificielle** d'Alyra. Il implÃ©mente un systÃ¨me de prÃ©diction du niveau calorique des recettes utilisant l'apprentissage automatique.

**CompÃ©tences Ã©valuÃ©es (Bloc 3 : Appliquer des techniques d'analyse IA via des algorithmes d'apprentissage automatique)** :

- **C1** : SÃ©lectionner l'algorithme d'apprentissage le plus adaptÃ© en comparant les performances et les caractÃ©ristiques des diffÃ©rentes familles d'algorithmes afin d'apporter une rÃ©ponse pertinente Ã  la problÃ©matique mÃ©tier rencontrÃ©e
- **C2** : PrÃ©parer et transformer des donnÃ©es en utilisant des techniques de prÃ©traitement (preprocessing) pour les adapter aux spÃ©cificitÃ©s du modÃ¨le d'apprentissage automatique choisi
- **C3** : EntraÃ®ner un modÃ¨le d'apprentissage automatique en optimisant une loss function (fonction de coÃ»t) Ã  partir des donnÃ©es d'entraÃ®nement afin de permettre Ã  l'algorithme d'effectuer le moins d'erreurs possibles selon des indicateurs de succÃ¨s clairement dÃ©finis

## ğŸ¯ Vue d'ensemble

SystÃ¨me d'intelligence artificielle qui **prÃ©dit les calories des recettes** Ã  partir de leurs ingrÃ©dients et instructions. Ce projet explore **deux approches complÃ©mentaires** : classification par catÃ©gories et rÃ©gression pour prÃ©diction directe des valeurs caloriques.

## ğŸ“ˆ Ã‰volution du projet - De la Classification Ã  la RÃ©gression

Ce projet documente une **approche itÃ©rative** avec deux phases principales d'expÃ©rimentation.

### ğŸ”¸ Phase 1 : Approche Classification (RÃ©alisÃ©e)

**Transformation en problÃ¨me de classification**

- **Approche** : Conversion des calories (variable continue) en **3 catÃ©gories** : BAS/MOYEN/HAUT
- **MÃ©thode de catÃ©gorisation** : Par percentiles (33% chacune)
  - BAS : < 215 calories
  - MOYEN : 215-430 calories
  - HAUT : > 430 calories
- **Architecture** : `TF-IDF (500 features) + Features nutritionnelles (15) â†’ XGBoost`

**RÃ©sultats obtenus**

- **Performance** : 43% d'accuracy (vs 33% alÃ©atoire)
- **AmÃ©lioration** : +30% par rapport au hasard
- **Temps d'entraÃ®nement** : ~15 minutes

**âœ… Avantages observÃ©s**

- InterprÃ©tabilitÃ© Ã©levÃ©e des catÃ©gories
- Logique nutritionnelle claire
- XGBoost performant sur features sparses (TF-IDF)

**âŒ Limites identifiÃ©es**

- **Perte d'information** : La discrÃ©tisation efface les nuances entre 214 et 216 calories
- **FrontiÃ¨res arbitraires** : Une recette Ã  214 cal (BAS) vs 216 cal (MOYEN) sont trÃ¨s proches
- **GranularitÃ© insuffisante** : Impossible de distinguer 200 cal vs 400 cal dans la mÃªme catÃ©gorie
- **Performance plafonnÃ©e** : 43% semble Ãªtre le maximum atteignable avec cette approche

### ğŸ”¸ Phase 2 : Approche RÃ©gression (Ã€ explorer)

**Retour Ã  la prÃ©diction continue**

- **Approche** : PrÃ©diction directe des **valeurs caloriques continues**
- **Preprocessing** : Normalisation `log1p(calories)` pour gÃ©rer la distribution asymÃ©trique
- **Architecture** : `TF-IDF + Features nutritionnelles â†’ RÃ©gresseurs ML`

**RÃ©gresseurs candidats Ã  tester**

- **XGBoost Regressor** : Extension naturelle de notre approche classification
- **Random Forest Regressor** : Robuste, parallÃ©lisable, moins d'overfitting
- **SVR (Support Vector Regression)** : Efficace sur features sparses

**Avantages attendus**

- **PrÃ©cision granulaire** : Distinction fine entre 200 et 210 calories
- **MÃ©triques continues** : MAE, RMSE plus intuitives que l'accuracy
- **Pas de perte d'information** : Conservation de toute la richesse des donnÃ©es
- **Applications pratiques** : PrÃ©dictions exploitables directement

**DÃ©fis Ã  relever**

- **Distribution asymÃ©trique** : Transformation log1p nÃ©cessaire
- **Outliers caloriques** : Gestion des recettes extrÃªmes (>2000 cal)
- **Ã‰valuation complexe** : DÃ©finir une erreur acceptable (Â±50 cal ?)

## ğŸ”¬ Comparaison Classification vs RÃ©gression

| Aspect                     | Classification (Phase 1)    | RÃ©gression (Phase 2)         |
| -------------------------- | --------------------------- | ---------------------------- |
| **Variable cible**         | 3 catÃ©gories (BAS/MOY/HAUT) | Calories continues           |
| **Preprocessing cible**    | Percentiles 33%             | log1p(calories)              |
| **MÃ©trique principale**    | Accuracy (43%)              | MAE/RMSE (Ã  dÃ©terminer)      |
| **InterprÃ©tabilitÃ©**       | Excellente                  | Bonne                        |
| **PrÃ©cision**              | GrossiÃ¨re (3 niveaux)       | Fine (valeur exacte)         |
| **Perte d'information**    | âš ï¸ Ã‰levÃ©e                   | âœ… Minimale                  |
| **Applications pratiques** | Recommandations gÃ©nÃ©rales   | Calculs nutritionnels prÃ©cis |
| **ComplexitÃ© Ã©valuation**  | Simple                      | ModÃ©rÃ©e                      |

## ğŸ¯ Pourquoi ce changement d'approche ?

### **Limitations de la classification observÃ©es**

1. **FrontiÃ¨res arbitraires** : 214 cal (BAS) vs 216 cal (MOYEN) - diffÃ©rence non significative
2. **GranularitÃ© insuffisante** : 200 cal et 400 cal dans la mÃªme catÃ©gorie "BAS"
3. **Performance plafond** : 43% semble Ãªtre le maximum avec la discrÃ©tisation
4. **Usage limitÃ©** : Applications pratiques nÃ©cessitent des valeurs prÃ©cises

### **Avantages attendus de la rÃ©gression**

1. **PrÃ©cision mÃ©tier** : PrÃ©diction directe utilisable en nutrition
2. **Pas de perte d'information** : Conservation de toute la richesse des donnÃ©es
3. **MÃ©triques intuitives** : "Erreur moyenne de Â±45 calories" vs "43% d'accuracy"
4. **FlexibilitÃ© d'usage** : Peut Ãªtre convertie en catÃ©gories a posteriori si besoin

## ğŸ“Š StratÃ©gie d'Ã©valuation pour la rÃ©gression

### **MÃ©triques principales**

- **MAE (Mean Absolute Error)** : Erreur moyenne en calories
- **RMSE (Root Mean Square Error)** : PÃ©nalise plus les grosses erreurs
- **MAPE (Mean Absolute Percentage Error)** : Erreur relative

### **Seuils d'acceptabilitÃ©**

- **Excellent** : MAE < 50 calories (Â±50 cal)
- **Bon** : MAE < 100 calories (Â±100 cal)
- **Acceptable** : MAE < 150 calories (Â±150 cal)
- **Baseline** : MAE moyenne = 200-300 calories

### **Preprocessing de la cible**

```python
# Transformation log pour normaliser la distribution
y_log = np.log1p(df['calories'])  # log(1 + calories)

# AprÃ¨s prÃ©diction, retour aux valeurs originales
calories_pred = np.expm1(y_pred)  # exp(pred) - 1
```

## ğŸ› ï¸ Pipeline de dÃ©veloppement prÃ©vu

### **Phase 2A : baseline RÃ©gression**

1. **Linear Regression (Ridge)** : Baseline rapide
2. **Random Forest Regressor** : RÃ©fÃ©rence robuste
3. **Analyse des rÃ©sidus** : Identification des patterns d'erreur

### **Phase 2B : optimisation AvancÃ©e**

1. **XGBoost Regressor** : Fine-tuning hyperparamÃ¨tres
2. **Feature Engineering** : Ratios nutritionnels optimisÃ©s
3. **Ensemble Methods** : Combinaison des meilleurs modÃ¨les

## ğŸ“š Structure du projet Ã©volutive

```
itadaki_ML/
â”œâ”€â”€ ğŸ““ NOTEBOOKS
â”‚   â”œâ”€â”€ calorie_prediction_classification_xgboost.ipynb  # âœ… Phase 1 - Classification
â”‚   â”œâ”€â”€ calorie_prediction_regression_baseline.ipynb    # ğŸ”„ Phase 2A - Baseline rÃ©gression
â”‚   â””â”€â”€ calorie_prediction_regression_advanced.ipynb    # ğŸ“‹ Phase 2B - Optimisation
â”œâ”€â”€ ğŸ“ DONNÃ‰ES
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ RAW_recipes.csv                             # Dataset original
â”œâ”€â”€ ğŸ“ MODÃˆLES
    â””â”€â”€ models/                                         # ModÃ¨les de classification et regression

```

## ğŸ“¥ Dataset

**Food Ingredients Dataset** (source Kaggle ou Ã©quivalent)

- **228,430 recettes uniques** avec ingrÃ©dients et instructions
- **Classification calorique** : BAS (<215 cal), MOYEN (215-430 cal), HAUT (>430 cal) (via percentile)
- **IngrÃ©dients dÃ©taillÃ©s** en format texte
- **Instructions complÃ¨tes** de prÃ©paration
- **Distribution Ã©quilibrÃ©e** des classes

## ğŸ—ï¸ Choix d'architecture : pourquoi XGBoost + TF-IDF ?

### ğŸ¯ Comparaison des approches ML

| Approche                   | Avantages                    | InconvÃ©nients            | Performance | Temps    |
| -------------------------- | ---------------------------- | ------------------------ | ----------- | -------- |
| **XGBoost + TF-IDF** âœ…    | Ã‰quilibre performance/temps  | HyperparamÃ¨tres nombreux | 43-48%      | 15-20min |
| **Random Forest + TF-IDF** | Robuste, moins d'overfitting | Plus lent, moins prÃ©cis  | 40-45%      | 20-25min |

### ğŸ” Justification du choix XGBoost + TF-IDF

#### âœ… **Avantages dÃ©cisifs**

1. **ğŸ¯ AdaptÃ© aux features sparses** : TF-IDF gÃ©nÃ¨re des matrices trÃ¨s sparses, XGBoost les gÃ¨re efficacement

2. **ğŸš€ Performance/temps optimal** :

   - **Performance** : 43-48% (correct pour ce problÃ¨me difficile)
   - **Temps** : 15-20 minutes (acceptable pour l'itÃ©ration)
   - **InterprÃ©tabilitÃ©** : Feature importance directement disponible

3. **ğŸ”§ FlexibilitÃ©** : HyperparamÃ¨tres nombreux pour fine-tuning
   - **learning_rate** : ContrÃ´le de l'overfitting
   - **max_depth** : ComplexitÃ© des arbres
   - **n_estimators** : Ã‰quilibre performance/temps

#### âŒ **Pourquoi pas les autres (en cours de test) ?**

##### **Random Forest** - Performance insuffisante

- **ğŸ¯ Performance** : 2-3% de moins que XGBoost
- **â±ï¸ Plus lent** : Pas de parallÃ©lisation GPU
- **ğŸ”§ Moins de contrÃ´le** : HyperparamÃ¨tres moins nombreux

### ğŸ¯ Pourquoi ce problÃ¨me est difficile ?

#### **Limites intrinsÃ¨ques du dataset**

1. **ğŸ¥„ QuantitÃ©s manquantes** : "flour, sugar, butter" â†’ pancake ou gÃ¢teau ?
2. **ğŸ”¥ MÃ©thodes de cuisson** : grillÃ© vs frit change tout
3. **ğŸ“ Portions variables** : mÃªme recette, calories diffÃ©rentes
4. **ğŸŒ VariabilitÃ© culturelle** : "rice" peut Ãªtre 100-300 calories

#### **Contexte rÃ©aliste d'accuracy**

- **ğŸ² Baseline alÃ©atoire** : 33% (3 classes Ã©quilibrÃ©es)
- **ğŸ‘¨â€ğŸ³ Performance humaine estimÃ©e** : 60-70% (chef expÃ©rimentÃ©)
- **ğŸ¤– Notre modÃ¨le** : 43-48% â†’ **amÃ©lioration de 30-45%** vs alÃ©atoire
- **ğŸ¯ Performance raisonnable** pour un problÃ¨me si complexe

## ğŸ“ˆ RÃ©sultats et insights

### Principales dÃ©couvertes

1. **ğŸ“Š Features TF-IDF dominantes** : Les ingrÃ©dients individuels (butter, sugar, lettuce) sont plus discriminants que les features nutritionnelles
2. **ğŸ” ContextualitÃ© importante** : "lettuce" dans burger vs salade change tout
3. **âš–ï¸ Ã‰quilibre ML/Expert** : Approche hybride nÃ©cessaire pour performance optimale
4. **ğŸ¯ Hard cases rÃ©vÃ©lateurs** : Le modÃ¨le excelle sur les cas "Ã©vidents" (salade vs gÃ¢teau)

### MÃ©triques par classe

```
              precision    recall  f1-score   support
         bas       0.48      0.54      0.51     15208
       moyen       0.43      0.31      0.36     15032  # Classe la plus difficile
        haut       0.38      0.44      0.41     15446
```

**Insight clÃ©** : La classe MOYEN est la plus difficile (frontiÃ¨re floue entre BAS et HAUT)

### Features les plus discriminantes

1. **yellow_onion** (21.4%) - IngrÃ©dient de base vs sophistiquÃ©
2. **garlic** (11.0%) - Aromate courant
3. **dried_oregano** (10.3%) - Ã‰pice mÃ©diterranÃ©enne
4. **butter** (8.2%) - MatiÃ¨re grasse Ã©vidente
5. **sugar** (7.1%) - Sucrant direct

## ğŸ“ Apprentissages et limites

### âœ… RÃ©ussites

- **Baseline solide** : 43% sur problÃ¨me complexe
- **InterprÃ©tabilitÃ©** : Top features nutritionnellement logiques
- **Temps raisonnable** : 15-20min d'entraÃ®nement
- **Approche progressive** : Du simple au complexe

### âš ï¸ Limites identifiÃ©es

- **QuantitÃ©s manquantes** : Impact majeur sur la prÃ©cision
- **AmbiguÃ¯tÃ© MOYEN** : Classe intermÃ©diaire difficile Ã  discriminer
- **Biais contextuel** : Certains ingrÃ©dients mal associÃ©s
- **Dataset size** : Plus de donnÃ©es amÃ©liorerait les performances

### ğŸš€ AmÃ©liorations futures

1. **ğŸ”¢ QuantitÃ©s** : Dataset avec quantitÃ©s prÃ©cises
2. **ğŸ“¸ Images** : Ajout de computer vision pour validation
3. **ğŸ½ï¸ Contexte** : Utiliser les instructions Ã  la place des ingrÃ©dients pour informations de cuisson et de quantitÃ© (demande traitement NLP plus lourd)

## ğŸ“š Technologies utilisÃ©es

- **Scikit-learn** : TF-IDF, preprocessing, mÃ©triques
- **XGBoost** : Algorithme de classification principal
- **Pandas/NumPy** : Manipulation de donnÃ©es
- **Matplotlib/Seaborn** : Visualisations et analyses
- **SHAP** : InterprÃ©tabilitÃ© du modÃ¨le
- **Jupyter** : Environnement de dÃ©veloppement

## ğŸ¯ Conclusions et perspectives

### **Apprentissages de la Phase 1 (Classification)**

- L'**approche XGBoost + TF-IDF** fonctionne bien pour la classification
- **43% d'accuracy** reprÃ©sente une amÃ©lioration significative (+30% vs alÃ©atoire)
- Les **features nutritionnelles engineerÃ©es** apportent de la valeur
- **Limitation fondamentale** : La discrÃ©tisation fait perdre trop d'information

### **HypothÃ¨ses pour la Phase 2 (RÃ©gression)**

- La **prÃ©diction continue** devrait capturer plus de nuances
- **Transformation log1p** devrait normaliser la distribution des calories
- **MÃ©triques MAE/RMSE** seront plus parlantes que l'accuracy
- **Applications pratiques** directement exploitables

### **Impact mÃ©tier attendu**

- **PrÃ©cision nutritionnelle** : Calculs caloriques utilisables en pratique
- **FlexibilitÃ© d'usage** : Conversion possible en catÃ©gories selon le besoin
- **Ã‰volutivitÃ©** : Base solide pour d'autres prÃ©dictions nutritionnelles (protÃ©ines, lipides...)

---

**Projet rÃ©alisÃ© dans le cadre de la certification DÃ©veloppeur IA - Alyra**

_La progression Classification â†’ RÃ©gression illustre parfaitement l'approche itÃ©rative et l'amÃ©lioration continue en Machine Learning._
